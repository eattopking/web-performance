### node 检测进程分配内存大小和进程当前内存使用情况

使用process.memoryUsage获取

 [详细使用链接](https://www.lema.fun/post/47e93hs9s)

### node 四种创建子进程的方法的理解
1. execFile 和 exec, 他们都是可以执行主命令的可执行文件或者主命令的环境变量
2. execFile 只需要将shell参数设置为true, 就可以和exec一样将主命令和参数放在一个字符串中执行了
3. 所有创建子进程的方法都会返回子进程实例, 都可以监听error、exit、close等事件, 都可以监听stdout、stderr 标准输出、标准错误
4. spawn 就像是execFile和fork的结合体, 只是spawn没有回调参数, spawn可以设置shell参数, 直接当作exec使用

### node中 I/O操作 和 CPU密集型操作

1. cpu使用过多的操作js计算, 就像大循环比较, 这样就会占用线程, 这就会阻塞循环后面的代码执行, 也会导致异步I/O操作后的回调函数无法被执行

2. I/O操作就是读写文件的操作

3. cpu占用就是js计算过多占用cpu比较多, 本身和I/O操作没有关系, 对I/O没有任何影响, 执行如果大循环后面有I/O操作, 在大循环结束之前无法被触发

### commonjs 规范的理解

1. node是根据commonjs规范实现的
2. commonjs module 只是对commonjs 规范中的一个模块规范, commonjs规范还有很多其他规范, 比如文件系统规范、I/O规范、Packages规范(包规范, npm就是根据这个规范实现的node包管理系统)
3. js最主要的三个规范分别是 W3c规范(主要是bom和dom根据这个规范实现)、Ecmascript规范(主要是js的一些语法根据这个规范实现, 还有esmoudle也是根据这个规范实现)、Commonjs规范

### node 模块化理解
1. node模块化加载(require)有三个流程, 路径分析(确定加载的路径)、文件定位(找到文件的具体位置)、编译执行(就只把加载的js文件模块的导致部分执行的代码执行一遍在导出结果), 最后获取到导出的模块

2. node有两种模块 node中本来就有的叫做核心模块(加载核心模块没有路径分析、文件定位、编译执行这三个流程, 因为已经是编译执行完的了)、 还有就是我们自己写的js文件, 叫做文件模块(文件模块的加载过程就是经历上面三个步骤了, 但是不管是核心模块还是文件模块加载过一次之后导出结果都会被缓存, 所以第二次加载就同一个文件模块, 就不会路径分析、文件定位、编译执行这三个流程了)


#### npm 理解
1. npm install 执行时，如果 package.json 和 package-lock.json 中的版本兼容，会根据 package-lock.json 中的版本下载；如果不兼容，将会根据 package.json 的版本，更新 package-lock.json 中的版本，已保证 package-lock.json 中的版本兼容 package.json。

2. package-lock.json 就是用来锁定项目中依赖的版本, 还有依赖的依赖的版本, 保证所以人在相同项目中npm install 安装的依赖都是版本相同的

3. 如果package.json中有更新, 更新的按照package.json中版本进行安装, 然后将版本信息更新到package-lock.json中, 其他没有更新的依赖还是按照package-lock.json中锁定的版本安装

4. npm3及以后的node_modules安装依赖后层级设置, 按照顺序安装依赖, 正常都是安装到第一层级, 如果有多个依赖的依赖相同的包的不同版本, 后面安装的依赖就在自己的安装到node_modules的目录中在创建一个node_modules目录用户安装不同版本的依赖, 前面的那个依赖的依赖还是安装在第一层

### node中流(stream)的理解

什么是流, 流就是通过片段的形式持续输出和写入内容, 提高效率了, 而不需要全部都准备好在输出或者写入, 准备好一部分就输出或者写入一部分

1. stream的主要api有pipe通过管道读取可读流中数据,  stream1.pipe(stream2) stream2通过管道读取stream1可读流中的数据,
pipe 方法就是将可以可读流和可写流的读取这套流程封装了一下, 并且处理了这个过程中的异常, 让使用者更加方便的读写

2. 可读流的特有操作

```
stream.push(111);  向可读流中写入数据
stream.read();  获取可读流中内容, 不指定参数size(一次读多少字节), 直接取出所有内容


可读流分为流动态和静止态,只有流动态的时候才可以从中读取内容
stream.pause(); 设置可读流静止态
stream.resume(); 设置可读流流动态

可读流在注册data事件后, 会自动切换成流动态, 不断触发data事件, 回调返回读到的内容
stream.on('data', (data) => {
  data是可读流中读取到的内容
});

可读流内容被读取完毕后, 会触发可读流的end事件
stream.on('end', () => {
  可读流被读取完了触发end事件
});

可读流当存在内容的时候readable事件就会调用, 然后我们就可以通过stream.read()获取流内容


```

3. 可写流的特有操作
```
stream.write(111)  向可写流中写入数据
当可写流写入太快的时候stream.write会返回false, 这个时候就不能在写入了,否则会报错, 所以需要设置可读流为静止态
只有当可写流调用 drain 事件的时候表示可写流可以继续写入
stream.on('drain', () => {
  可写流可以继续写入了, 将可读流设置为流动态继续向可写流中写入
})

stream.end()  设置可写流不能在写入了

可写流的finish的事件, 表示可写流已经写入完毕

stream.on('finish', () => {
 
})

可写流的error的事件, 表示可写流写入过程中报错
stream.on('error', () => {
 
})

可写流的destroy方法
```
4. 流的种类

```
Readable: 可以通过管道读取、但不能通过管道写入的流（可以接收数据，但不能向其发送数据）。 当推送数据到可读流中时，会对其进行缓冲，直到使用者开始读取数据为止。
Writable: 可以通过管道写入、但不能通过管道读取的流（可以发送数据，但不能从中接收数据）。
Duplex: 可以通过管道写入和读取的流，基本上相对于是可读流和可写流的组合。
Transform: 类似于双工流、但其输出是其输入的转换的转换流。
```
5. 很多node 原生api 有流的能力

### node 句柄理解

句柄是一种可以用来标识资源的引用，它的内部包含了指向对象的文件描述符。比如句柄可以用来标识一个服务器端socket对象、一个客户端socket对象、一个UDP套接字、一个管道等。

### node 进程间通信理解

1. node 进程间通信使用IPC通信, 只有fork出来的子进程能和主进程通信

2. 通信的send方法, 只能传递消息和特定类型的句柄, 例如一个  const server = createServer(), 得到的server实例就是一个句柄

3. node能够实现IPC通信是通过libuv实现的, node对系统的底层是操作, 例如文件操作也是通过libuv实现的, libuv是通过c++实现的

4. fork出来的子进程和父进程建立连接的过程: 首先父进程将建IPC通道, 然后在创建子进程的时候将IPC通道的文件描述符告知子进程, 然后子进程根据文件描述符找到已有的IPC通道和父进程建立连接

5. 通过send方法在进程中只是可以传递消息, 不能传递对象, 能够传递对象只是内部处理后给到使用者的假象, 通过IPC通道传递的消息都是需要通过JSON.stringfy序列化之后在传递的, send方法在通过IPC通道传递之前会将需要传递的内容, 组装成两个对象一个是handler, 一个message, 子进程就是根据父进程传递过来的JSON.stringfy之后的message配置还原父进程传递的真实内容, 子进程发给父进程的同理
```
message的结构如下: 

{
    cmd:'NODE_HANDLE',
    type:'net.Server',
    msg:message
}

```

6. 所以说send不能发送所有的句柄, 因为需要还原的支持, 所以node就是根据JOSN.parse解析message的配置和IPC通道文件描述符还原send方法传递的对应内容

### node Buffer 理解
1. buffer 是一个可以根据编码类型或者说字符集转换字符串并进行存储的数据结构

2. buffer的结构和数组类似, 都是可以通过索引取值

3. buffer 的每一项都是一个字节(B), 每一项都是表示字节编码(就是转换为对应编码类型后每个字节对应的编码)

4. 1个字节 等于 8bit(位)
